{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348acc51",
   "metadata": {},
   "source": [
    "# Prologue\n",
    "\n",
    "### This prologue chapter will describe what progress is made and what experiments are tried before the individual project is getting started.\n",
    "\n",
    "I started this semester by looking through some of the datasets on Kaggle, but most of these datasets have many features and lots of data. But with all beginnings it is a good thing to start with something easy to predict and visualize.\n",
    "\n",
    "The main experiment in the prologue will be trying to find a Kaggle dataset that has atleast a a little bit of a linear connection with the outcome and a single feature. This makes it possible to try out one of the simplest machine learning algorithms, Linear Regression. Because linear regression with only a single feature is so simple compared to the other algorithms  the plan is to write all the code for this algorithm from scratch to try and get a deeper understanding of how a computer can 'learn' things. Then later when the individual project is started the hope is that this deeper understanding can help me when I start using libraries to do the machine learning algorithms for me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bef2d2",
   "metadata": {},
   "source": [
    "## Prologue backlog\n",
    "- [x] Create a Jupyter notebook\n",
    "- [x] Find a dataset with a possible linear correlation\n",
    "- [x] Split the data in training and test data\n",
    "- [x] Write the linear regression code\n",
    "- [x] Train and test with the data\n",
    "- [x] Visualize the results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616fac87",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "Prior to this prologue I watched a few videos on linear regression to get an idea about how it works and the the math involved.\n",
    "[Linear Regression with Ordinary Least Squares Part 1](https://www.youtube.com/watchv=szXbuO3bVRk&ab_channel=TheCodingTrain)\n",
    "In this video series from the coding train he uses the example of the linear connection between the temperature outside and the amount of ice cream sold. Of course many more features could be included such as the day of the week, humidity etc and it would likely give a more accurate prediction, but for learning purposes and to get started with linear regression just looking at the temperature will suffice. \n",
    "\n",
    "Kaggle has a lot of complicated datasets and after looking at datasets for a while before starting this prologue I decided to just look for the example given in the Coding Train video. And this is the dataset I found: [Ice Cream Revenue](https://www.kaggle.com/datasets/vinicius150987/ice-cream-revenue). The only problem I have with this dataset is that it only includes the temperature and the revenue. I would have liked more features to try and make a correlation heatmap to see if the temperature would be the biggest factor in determining the revenue. I will still try to do it with this dataset just to see what happens.\n",
    "\n",
    "The revenue in the dataset is in US dollars and the temperature is in degrees Celcius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3144498d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (500, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.566884</td>\n",
       "      <td>534.799028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.005191</td>\n",
       "      <td>625.190122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.790554</td>\n",
       "      <td>660.632289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.595335</td>\n",
       "      <td>487.706960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.503498</td>\n",
       "      <td>316.240194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature     Revenue\n",
       "0    24.566884  534.799028\n",
       "1    26.005191  625.190122\n",
       "2    27.790554  660.632289\n",
       "3    20.595335  487.706960\n",
       "4    11.503498  316.240194"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = dataframe (Data sturcture in pandas)\n",
    "df = pd.read_csv('Datasets/IceCreamData.csv')\n",
    "print('Shape: ' + str(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13055b",
   "metadata": {},
   "source": [
    "## Splitting the dataset\n",
    "\n",
    "To have unseen data to verify the results the data will be split up in training and test data. For now the data will be arbitrarily split into **80% training data and 20% test data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf32cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (400, 2)\n",
      "Test data shape: (100, 2)\n",
      "Split percentage (Training|Test) (80|20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2)\n",
    "print('Training data shape: {}'.format(train_data.shape))\n",
    "print('Test data shape: {}'.format(test_data.shape))\n",
    "train_percent = math.floor(train_data.shape[0] / df.shape[0] * 100)\n",
    "test_percent = math.floor(test_data.shape[0] / df.shape[0] * 100)\n",
    "print('Split percentage (Training|Test) ({}|{})'.format(train_percent, test_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bebe055",
   "metadata": {},
   "source": [
    "## Plotting the dataset and predictions\n",
    "\n",
    "I am going to plot the dataset to see if there is a linear correlation between the temperature and the revenue. The expectation is that there will be a linear correlation since the description of this dataset in Kaggle mentioned that the dataset 'is a simple sample dataset for training'. There could be a few outliers because the data is split up on revenue per day, but it also could be removed by the owner of the dataset because the dataset is just for beginners to get started.\n",
    "\n",
    "And obviously the expectation is that the higher the temperature the higher the revenue will be. This means that the line that will be predicted will look something like this: ![Expected Line](Images/TemperatureRevenueExpected.png)\n",
    "The formula for a line is \\begin{equation} y = mx + b\n",
    "\\end{equation} and my prediction is that the value for b is going to be low as it is the intersection with the y-axis or the value when x = 0 which in this case means 0 degrees celcius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f5ed81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# layout for all the graphs\n",
    "plt_bg_color = '#303845'\n",
    "plt_alpha = 0.08\n",
    "plt_outline_color = 'white'\n",
    "\n",
    "def setup_layout():\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor(plt_outline_color)\n",
    "    fig.patch.set_alpha(plt_alpha)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.set_facecolor(plt_bg_color)\n",
    "\n",
    "def setup_graph():\n",
    "    plt.xlabel('Temparature')\n",
    "    plt.ylabel('Revenue')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "setup_layout()\n",
    "plt.title('The complete dataset')\n",
    "plt.scatter(df['Temperature'], df['Revenue'], color = '#2071A9', label = 'All data')\n",
    "setup_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750370d",
   "metadata": {},
   "source": [
    "As expected the data points are clearly scattered in close proximity of a line. There are also no real outliers, which is not what I hoped because I would have liked to get some practice removing outliers from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8ab95b",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "In my understanding linear regression is a way for a machine to try and find the best linear formule for the training data that is given. Where the x-axis is the feature that is used for the prediction and the y-axis the value that is being predicted. The formula for a line is y = mx + b and since x is the input linear regression tries to find the best m and b value for the given data. After the best line for the data is found new input data can be given and the line can predict what the output will be.  \n",
    "\n",
    "There also seem to be multiple methods to apply linear regression:\n",
    "* Ordinary least squares\n",
    "* Gradient descend\n",
    "\n",
    "There might me more than the once listed above but these are the ones I found so far.\n",
    "For this prologue I am atleast going to look at the ordinary least squares method first, because I already looked at gradient descend before starting this semester and the math can become very complex and gradient descend can also be used when training a neural network, so maybe something to look at later in the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a5d49",
   "metadata": {},
   "source": [
    "## Ordinary least squares\n",
    "\n",
    "Ordinary least squares (OLS) is a way of estimating the unknown parameters (m and b) in a linear regression model. The algorithm that I am going to use for OLS is: ![OLS algorithm](Images/OlsCalcM.png)This algorithm was explained in part 2 of the Coding Train series [Linear Regression with Ordinary Least Squares Part 2 ](https://www.youtube.com/watch?v=_cXuvTQl090&ab_channel=TheCodingTrain) The algorithm looks at the squared sum of all the errors and tries to minimize the sum. The errors get squared to make the negative numbers (the errors below the predicted line) not cancel out the positive errors above the line. \n",
    "\n",
    "![OLS error](Images/OlsError.png)\n",
    "\n",
    "The OLS algorithm needs the average of all the x and y values so I get those from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48ef167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x average: 22.310602293095 | y average: 524.3263140606501 \n"
     ]
    }
   ],
   "source": [
    "# There must be a more proper way to get the average of a DataFrame / series\n",
    "\n",
    "x_train_data = train_data.loc[:,'Temperature'].tolist()\n",
    "y_train_data = train_data.loc[:, 'Revenue'].tolist()\n",
    "x_avg = sum(x_train_data) / len(x_train_data)\n",
    "y_avg = sum(y_train_data) / len(y_train_data)\n",
    "print('x average: {} | y average: {} '.format(x_avg, y_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3df985",
   "metadata": {},
   "source": [
    "After calculating the averages it is possible to apply the rest of the formula on the training data.\n",
    "m is calculated with the formule shown earlier.\n",
    "When m is known b is easy to calculate. Because a linear formula is **y = mx+b**, which can be written as **b + mx = y** if both sides are reduced with mx we get the formula for b. **b = y - mx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6c006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 21.41 * x + 46.71\n"
     ]
    }
   ],
   "source": [
    "m = b = 0\n",
    "\n",
    "# Ordinary least squares\n",
    "numerator = 0 # teller\n",
    "denominator = 0 # noemer\n",
    "for i in range(len(x_train_data)):\n",
    "    x = x_train_data[i]\n",
    "    y = y_train_data[i]\n",
    "    numerator += (x - x_avg) * (y - y_avg)\n",
    "    denominator += (x - x_avg) ** 2\n",
    "m = numerator / denominator # could be scary if denominator is 0, but that is very unlikely \n",
    "b = y_avg - m * x_avg\n",
    "\n",
    "print('y = {} * x + {}'.format(round(m,2), round(b,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3791a36",
   "metadata": {},
   "source": [
    "If I did it right the best m value for the line is approximately **21.27** and the best b value would be approximately **49.18**. I don't have an idea on how to check if this is good or not or how to give it an accuracy score. But a good first indication might be too look at the average error between all points in the training and test data. The average error in the training data should be lower, but it might not be a huge difference without the outliers and a data set that fits linear regression so well.\n",
    "> After re-running the Kernel it seems that the data that is taken when splitting is random. This means that the results are not exactly the same everytime the Kernel runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85bf825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error in training data: 18.86 \n",
      "Average error in test data: 22.59\n"
     ]
    }
   ],
   "source": [
    "avg_error_train = 0;\n",
    "for i in range(len(x_train_data)):\n",
    "    x = x_train_data[i]\n",
    "    y = y_train_data[i]\n",
    "    avg_error_train += abs(y - (m * x + b))\n",
    "\n",
    "avg_error_train /= len(x_train_data)\n",
    "\n",
    "\n",
    "x_test_data = test_data.loc[:,'Temperature'].tolist()\n",
    "y_test_data = test_data.loc[:, 'Revenue'].tolist()\n",
    "avg_error_test = 0;\n",
    "\n",
    "for i in range(len(x_test_data)):\n",
    "    x = x_test_data[i]\n",
    "    y = y_test_data[i]\n",
    "    avg_error_test += abs(y - (m * x + b))\n",
    "\n",
    "avg_error_test /= len(x_test_data)\n",
    "\n",
    "print('Average error in training data: {} \\nAverage error in test data: {}'\n",
    "      .format(round(avg_error_train,2), round(avg_error_test,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcdca5",
   "metadata": {},
   "source": [
    "To figure out if what I did was even remotely right I will try to loop through all reasonable values for m and b to see if I can find a line that can better represent the data. I get that this method is flawed because I it will only loop through integer numbers an ignore decimal values. But it still should give an indication if the line that I found is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415acd27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest error found: 19.07913461848999\n",
      "LOS error: 18.860540894312415\n",
      "Difference: 0.21859372417757683\n"
     ]
    }
   ],
   "source": [
    "# bf = brute force\n",
    "avg_error_bf = avg_error_train + 1;  \n",
    "bf_errors = []\n",
    "\n",
    "\n",
    "for m_val in range(50):\n",
    "    for b_val in range(75):\n",
    "        avg_error_bf = 0\n",
    "        for i in range(len(x_train_data)):\n",
    "            x = x_train_data[i]\n",
    "            y = y_train_data[i]\n",
    "            avg_error_bf += abs(y - (m_val * x + b_val))\n",
    "        \n",
    "        avg_error_bf /= len(x_train_data)\n",
    "        bf_errors.append(avg_error_bf)\n",
    "        if avg_error_bf <= avg_error_train:\n",
    "             print('A BETTER LINE FOUND WITH M: {} AND B: {} avg error {}'.format(rand_m, rand_b, avg_error_random))\n",
    "\n",
    "print('Lowest error found: {}\\nLOS error: {}\\nDifference: {}'\n",
    "      .format(\n",
    "          min(bf_errors),\n",
    "          avg_error_train,\n",
    "          min(bf_errors) - avg_error_train)\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d668141",
   "metadata": {},
   "source": [
    "This little test shows that there are atleast no rounded number within a reasonable range that fits the data closer than what I found using OLS. This result makes me think that I applied the algorithm correctly, but there still might be a better solution out there. \n",
    "\n",
    "And the difference between the brute force method and the OLS method is really low, in some splits less than 0.2. This was not what I expected. But OLS still gives a better result than this brute force method and will hold up better with a larger dataset, because the time to calculate the values doesn't increase exponentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1678be",
   "metadata": {},
   "source": [
    "The last way I will try to find if the results of the OLS algorithms are useful I will try to plot the test data and the prediction line in the same graph. If they overlap the line found by the algorithm is a good fit for the data. I didn't do this step earlier because I didn't know how to draw multiple things in a single graph, but after training more with the pandas course from Kaggle and reading documentation on the plotlib library I figured it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c9573f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Setting up the line\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m min_x \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m      5\u001b[0m max_x \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(min_x, max_x, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# create the outer points of the line\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Setting up the line\n",
    "min_x = df['Temperature'].min()\n",
    "max_x = df['Temperature'].max()\n",
    "x = np.linspace(min_x, max_x, 2) # create the outer points of the line\n",
    "\n",
    "def draw_prediction_graph(title, label, dataset, scatter_color):\n",
    "    setup_layout()\n",
    "    plt.title(title)\n",
    "    plt.scatter(dataset['Temperature'], dataset['Revenue'], color = scatter_color, label = label)\n",
    "    plt.plot(x, m * x + b, color = 'red', label = 'prediction', linewidth = 2)\n",
    "    setup_graph()\n",
    "    \n",
    "# Training data with prediction\n",
    "draw_prediction_graph('Training data with prediction line', 'Training data', train_data, 'blue')\n",
    "\n",
    "# Test data with prediction\n",
    "draw_prediction_graph('Test data with prediction line', 'Test data', test_data, 'cyan')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3de2f",
   "metadata": {},
   "source": [
    "## Prologue conclusion\n",
    "\n",
    "During this prologue I learned a lot: I managed to find a dataset that would be easy to startwith,  I started working with a Jupyter notebook and got used to using the Python syntax, I plotted graphs with the matplot library and split the dataset in test and training data and finally applied linear regression with the ordinary least squares method to calculate a line that fits the dataset. After that I validated my results by calculating the average error, trying out a brute force algorithm to see if my answer is reasonable and I plotted the prediction line against the data. And even though I succeeded with this dataset, the computer did not really learn, it just applied a mathemetical formula on all the given data at once to find the best line. \n",
    "During the rest of the semester I would also like to look at problems that are more complex and where the computer gradually gets better until it can confidently solve the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f825650",
   "metadata": {},
   "source": [
    "## Version control\n",
    "After writing the Prologue it seemed like a good idea to put the notebook into Git and onto Github for version management and to have an online backup. It is also good preperation for the group project that likely will also have a notebook on Github.\n",
    "\n",
    "As a software major I try not to overengineer the projects that I pursue during this semester I think putting the project on Github still adds value, especially for the group projects, but also in addition to the checkpoints that Jupyter creates.\n",
    "\n",
    "Because of my major it was easy to put the notebook into Git. The only downside is that because the notebook is a mixture of markdown and code spread over different cells, the changes are difficult to view. The solution I found was using a tool called [ReviewNB](https://app.reviewnb.com/) that lets you view the changes on Github. In the near future I would also like find a solution to view my changes locally before I push them to Github.\n",
    "\n",
    "After reading this [blog](https://blog.reviewnb.com/jupyter-version-control/) I found the option of adding [jupyterlab-git](https://github.com/jupyterlab/jupyterlab-git) to the notebook, but I couldn't get this to work. So instead I will use the merge editor from Visual Studio Code to deal with local merge requests in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cce6f4",
   "metadata": {},
   "source": [
    "## Inspiration\n",
    "\n",
    "The goal after writing the Prologue is to find inspiration for my individual challenge of the semester. Before the start of this semester I did a little bit of research into NN (neural network(s)) and I would like to learn more about how they can be applied and structured.\n",
    "\n",
    "Before the start of the semester I already followed youtubers that also made videos about AI, so that is the first place I went to for inspiration. I watched all the projects made by Code Bullet and the series about [Genetic Algorithms](https://www.youtube.com/playlist?list=PLRqwX-V7Uu6bJM3VgzjNV5YxVxUwzALHV) by The Coding Train. Here I learned that a genetic algorithms is basically a type of reinforcement learning that is trying to simulate the idea of evolution theory with code. I instantly got hooked on the idea of doing something with a genetic algorithm, because of a couple reasons:\n",
    "  - I find the idea of applying real world phenomena in code appealing;\n",
    "  - It is great for story telling and visualisation and validation, because when you do it right you can actually see the agents improving and evolving over time.\n",
    "  - The results can be fascinating, funny and unpredictable as the agents might try to cheat the system, fail horrible in the beginning or come up with revolutionary ideas while improving. \n",
    "  - A genetic algorithm can be used together with a neural network.\n",
    "  - Agents can become so good at some of the tasks that humans could never compare.\n",
    "  \n",
    "The projects that inspired me the most are:\n",
    "<br/>\n",
    "<br/>\n",
    "  **NeuroEvolution Flappy Bird from The Coding Train**\n",
    "![NeuroEvolution Flappy Bird](Images/FlappyBird.png)\n",
    " <br/>\n",
    "**NeuroEvolution Jump King from Code Bullet**\n",
    "![NeuroEvolution Jump King](Images/JumpKing.png)\n",
    "\n",
    "<br/>\n",
    "In one of the Code Bullet videos he mentioned that he is using an algorithm similar to what Open AI used to beat dota. I never heard of Open AI, but I know that Dota is a very hard game to play for a computer therefore I started looking into the projects build by open AI. There I found the following inpressive projects:\n",
    "\n",
    "**Open AI Five playing Dota 2**\n",
    "![Open AI Five playing Dota 2](Images/OpenAiDota.png)\n",
    "\n",
    "They also used NeuroEvolution and self play to teach AIs to play hide and seek.  \n",
    "\n",
    "**Open AI playing hide and seek**\n",
    "![Open AI playing hide and seek](Images/OpenAiHideAndSeek.png)\n",
    "\n",
    "These open AI projects are really impressive to me as Dota is very difficult to teach, because it is a really complex game with lots of variety and an environment that is constantly changing. It also is a team game requiring the bots to play well together.  \n",
    "\n",
    "The hide and seek game peaked my interests, because the different generations got placed in increasingly diffucult scenarios and everytime either the hiding (defending) or seeking (attacking) team came up with a new stratergy later generations of the other team would find a way to break the new found strategy. And eventually the attacking team even found a way to break the physics engine to surf on top of a box and jump over the walls set up by the defending team (shown in the image below).  \n",
    "\n",
    "**Attacking team cheating the system**\n",
    "![Attacking team box surfing hide and seek](Images/OpenAiBoxSurfing.png)\n",
    "\n",
    "Of course Open AI is a major company and this is unrealistic for my individual challenge, but the hope is that my individual challenge will also have the different generations show funny, genius or unexpected solutions that humans can learn from. I also think that AI works best when the powers of the AI and Humans are combined, so if time allows it I would also like to implement a way for humans to be in the created environment alongside the AI.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
